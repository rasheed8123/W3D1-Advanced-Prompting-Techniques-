# ğŸ§  Prompt Engineering Pipeline: Multi-Path Reasoning + Optimization

## ğŸ’¡ Overview
A local LLM-based system to solve structured reasoning problems using:
- Tree-of-Thought (ToT) prompting
- Self-Consistency voting
- Automated Prompt Optimization (OPRO)

## ğŸ§± Structure

project/
â”œâ”€â”€ main.py
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ tree_of_thought.py
â”‚ â”œâ”€â”€ optimizer.py
â”‚ â””â”€â”€ tinyllama_runner.py
â”œâ”€â”€ logs/
â”‚ â””â”€â”€ results.jsonl
â”œâ”€â”€ evaluation.py
â”œâ”€â”€ report.md
â””â”€â”€ README.md

yaml


---

## ğŸš€ How It Works

1. **ToT Prompting**: Generates multiple reasoning paths
2. **Voting**: Applies self-consistency to select a majority answer
3. **Optimization**: Refines prompt based on failures using LLM feedback

---

## ğŸ› ï¸ Usage

```bash
python main.py
You'll be prompted to enter a math/logic/code problem (e.g. Solve: 2(x + 3) = 16)

To evaluate performance:

bash

python evaluation.py
ğŸ“Š Evaluation Metrics
Accuracy (% correct)

Hallucination Rate

Reasoning Quality (manual review)

ğŸ”§ Dependencies
Python 3.10+

Ollama + TinyLlama installed locally

ğŸ‘¥ Authors
[Your Name]

Built as part of Misogi AI Week â€“ Day 3

ğŸ§ª Example
Input:

makefile

Solve: 2(x + 3) = 16
Output:

yaml

âœ… Final Answer: 5
Votes: {'5': 3, '6': 1, '9': 1}
ğŸ“˜ License
MIT

yaml


---

Would you like me to:
- Add code that *writes each task result to `logs/results.jsonl`*?
- Help generate 5 example tasks with expected answers for 
